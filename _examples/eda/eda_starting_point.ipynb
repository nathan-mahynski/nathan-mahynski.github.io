{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-your-data\" data-toc-modified-id=\"Load-your-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load your data</a></span></li><li><span><a href=\"#Pairplot-of-Features\" data-toc-modified-id=\"Pairplot-of-Features-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pairplot of Features</a></span></li><li><span><a href=\"#Look-at-Feature-Correlations\" data-toc-modified-id=\"Look-at-Feature-Correlations-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Look at Feature Correlations</a></span></li><li><span><a href=\"#Look-for-Multilabel-Class-Correlations-(Classification-Task-Only)\" data-toc-modified-id=\"Look-for-Multilabel-Class-Correlations-(Classification-Task-Only)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Look for Multilabel Class Correlations (Classification Task Only)</a></span></li><li><span><a href=\"#Look-for-Outliers\" data-toc-modified-id=\"Look-for-Outliers-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Look for Outliers</a></span></li><li><span><a href=\"#Look-for-Class-Imbalance-(Classification-Task-Only)\" data-toc-modified-id=\"Look-for-Class-Imbalance-(Classification-Task-Only)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Look for Class Imbalance (Classification Task Only)</a></span></li><li><span><a href=\"#Look-for-Natural-Clustering\" data-toc-modified-id=\"Look-for-Natural-Clustering-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Look for Natural Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Elbow\" data-toc-modified-id=\"Elbow-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Elbow</a></span></li><li><span><a href=\"#Silhouette-Curves\" data-toc-modified-id=\"Silhouette-Curves-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Silhouette Curves</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>PCA</a></span><ul class=\"toc-item\"><li><span><a href=\"#In-2D\" data-toc-modified-id=\"In-2D-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>In 2D</a></span></li><li><span><a href=\"#In-3D\" data-toc-modified-id=\"In-3D-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>In 3D</a></span></li></ul></li><li><span><a href=\"#LDA\" data-toc-modified-id=\"LDA-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>LDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#In-2D\" data-toc-modified-id=\"In-2D-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>In 2D</a></span></li><li><span><a href=\"#In-3D\" data-toc-modified-id=\"In-3D-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>In 3D</a></span></li></ul></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Decision Tree</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fit\" data-toc-modified-id=\"Fit-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Fit</a></span></li><li><span><a href=\"#Visualize\" data-toc-modified-id=\"Visualize-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Visualize</a></span></li></ul></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>KNN</a></span></li><li><span><a href=\"#Consider-Some-Performance-Metrics\" data-toc-modified-id=\"Consider-Some-Performance-Metrics-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Consider Some Performance Metrics</a></span></li><li><span><a href=\"#Jensen-Shannon-Divergence\" data-toc-modified-id=\"Jensen-Shannon-Divergence-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Jensen-Shannon Divergence</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-JSD-(OvO)\" data-toc-modified-id=\"Binary-JSD-(OvO)-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>Binary JSD (OvO)</a></span></li><li><span><a href=\"#Consider-some-polynomial-feature-engineering\" data-toc-modified-id=\"Consider-some-polynomial-feature-engineering-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;</span>Consider some polynomial feature engineering</a></span></li><li><span><a href=\"#OvA-JSD\" data-toc-modified-id=\"OvA-JSD-13.3\"><span class=\"toc-item-num\">13.3&nbsp;&nbsp;</span>OvA JSD</a></span><ul class=\"toc-item\"><li><span><a href=\"#Top-Features-Per-Class\" data-toc-modified-id=\"Top-Features-Per-Class-13.3.1\"><span class=\"toc-item-num\">13.3.1&nbsp;&nbsp;</span>Top Features Per Class</a></span></li><li><span><a href=\"#Look-for-interesting-clustering\" data-toc-modified-id=\"Look-for-interesting-clustering-13.3.2\"><span class=\"toc-item-num\">13.3.2&nbsp;&nbsp;</span>Look for interesting clustering</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example notebook including some basic EDA tools and techniques as described in my previous [tutorial](https://mahynski.github.io/tutorials/eda/).  This is not exhaustive and should be adapted to your goals.  Also see NIST's [engineering statistics handbook](https://www.itl.nist.gov/div898/handbook/eda/eda.htm) for more examples.\n",
    "\n",
    "\n",
    "* Prepared by Nathan A. Mahynski, Ph.D.\n",
    "* Last Updated: Feb. 2, 2021\n",
    "\n",
    "Be sure to first clone the necessary tools:\n",
    "~~~\n",
    "$ git clone https://github.com/mahynski/ml_inspector.git\n",
    "$ git clone https://github.com/mahynski/ml_utils.git\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Perform IDA first to clean things up, impute missing values, etc.\n",
    "\n",
    "X = pd.read_csv('/path/to/your/data')\n",
    "y = pd.read_csv('/path/to/your/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pairplot of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This can reveal any correlations between pairs of features.\n",
    "# Also compare with Spearman R results (presented next) \n",
    "X_net = X.copy()\n",
    "X_net['target'] = y\n",
    "\n",
    "ml_inspector.data.InspectData.pairplot(X_net, \n",
    "                                       vars=X.columns[:5], # Limit to the first 5 features \n",
    "                                       hue='target',\n",
    "                                       diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Look at Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Uses Spearman R + Ward clustering \n",
    "# Consider different potential cutoffs\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "selection = {}\n",
    "for cutoff in np.linspace(0, 5, 6):\n",
    "    selected_features, cluster_id_to_feature_ids = \\\n",
    "    ml_inspector.data.InspectData.cluster_collinear(X_std, \n",
    "                                                    feature_names=X.columns, \n",
    "                                                    t=cutoff,\n",
    "                                                    #figsize=(48, 32),\n",
    "                                                    figname=None)\n",
    "    selection[t] = {'selected_features':selected_features, 'cluster_id_to_feature_ids':cluster_id_to_feature_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for t in sorted(selection.keys()):\n",
    "    print(t, len(selection[t]['selected_features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Also see ml_inspector.data.InspectData.minimize_cluster_label_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for Multilabel Class Correlations (Classification Task Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multilabel classification you can look at how classes might be correlated\n",
    "# For example bird species, with colony.\n",
    "# This can also reveal gaps in sampling.\n",
    "\n",
    "c1_enc = LabelEncoder()\n",
    "c1_enc.fit(y['CLASS_1_NAME'])\n",
    "\n",
    "c2_enc = LabelEncoder()\n",
    "c2_enc.fit(y['CLASS_2_NAME'])\n",
    "\n",
    "matrix = np.zeros((len(c1_enc.classes_), len(c2_enc.classes_)))\n",
    "\n",
    "for c1, c2 in y[['CLASS_1_NAME', 'CLASS_2_NAME']].values:\n",
    "    matrix[c1_enc.transform([c1])[0], c2_enc.transform([c2])[0]] += 1\n",
    "    \n",
    "fig = plt.figure(figsize=(10,10))\n",
    "sns.heatmap(matrix, annot=True, ax=fig.gca(), xticklabels=c2_enc.classes_, yticklabels=c1_enc.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Look for Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider some examples:\n",
    "* [Outlier detection on a real data set](https://scikit-learn.org/stable/auto_examples/applications/plot_outlier_detection_wine.html?highlight=detect%20outliers)\n",
    "* [Novelty detection with Local Outlier Factor (LOF)](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_novelty_detection.html?highlight=detect%20outliers)\n",
    "* [Robust covariance estimation and Mahalanobis distances relevance](https://scikit-learn.org/stable/auto_examples/covariance/plot_mahalanobis_distances.html?highlight=detect%20outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Look for Class Imbalance (Classification Task Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.bar(\n",
    "    x=y.unique(),\n",
    "    height=[np.sum(y==class) for class in y.unique()]\n",
    ")\n",
    "plt.title('Observations in database')\n",
    "_ = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Look for Natural Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# If we see an elbos, that might be a natural number of clusters in the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X) # Standardize first\n",
    "ml_inspector.data.InspectData.cluster_elbow(X_std, clusters=np.arange(1,100,5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Silhouette Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(X)\n",
    "for nc in [3, 4, 5, 6, 10, 20]:\n",
    "    km = KMeans(n_clusters=nc,\n",
    "            init='k-means++',\n",
    "            n_init=10,\n",
    "            random_state=0)\n",
    "    plt.figure()\n",
    "    ml_inspector.data.InspectData.cluster_silhouette(X_std, km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## In 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline # 2D\n",
    "pca = PCA(n_components=2)\n",
    "ss = StandardScaler()\n",
    "X_proj = pca.fit_transform(ss.fit_transform(X))\n",
    "\n",
    "for class_ in y.unique():\n",
    "    mask = y == class_\n",
    "    plt.plot(X_proj[mask,0], X_proj[mask,1], 'o', label=class_)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('PCA on standardized dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## In 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D # 3D\n",
    "%matplotlib notebook\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "ss = StandardScaler()\n",
    "X_proj = pca.fit_transform(ss.fit_transform(X))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for class_ in y.unique():\n",
    "    mask = y == class_ \n",
    "    ax.scatter(X_proj[mask,0], X_proj[mask,1], X_proj[mask,2], label=class_)\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3')\n",
    "ax.set_title('PCA on standardized dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## In 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "%matplotlib inline # 2D\n",
    "ss = StandardScaler()\n",
    "lda = LDA(n_components=2, store_covariance=True)\n",
    "X_proj = lda.fit_transform(ss.fit_transform(X), y)\n",
    "\n",
    "for class_ in sorted(y.unique()):\n",
    "    mask = y == class_\n",
    "    plt.plot(X_proj[mask,0], X_proj[mask,1], 'o', label=class_)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('LDA on standardized dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## In 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D # 3D\n",
    "%matplotlib notebook\n",
    "\n",
    "ss = StandardScaler()\n",
    "lda = LDA(n_components=3, store_covariance=True)\n",
    "X_proj = lda.fit_transform(ss.fit_transform(X), y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for class_ in y.unique():\n",
    "    mask = y == class_ \n",
    "    ax.scatter(X_proj[mask,0], X_proj[mask,1], X_proj[mask,2], label=class_)\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3')\n",
    "ax.set_title('LDA on standardized dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, shuffle=True)\n",
    "\n",
    "max_depth = np.arange(1,10)\n",
    "\n",
    "test_acc, train_acc = [], []\n",
    "for md in max_depth:\n",
    "    tree = DecisionTreeClassifier(max_depth=md, class_weight=None) # Can adjust class weighting\n",
    "    # No need to standardize\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    test_acc.append(tree.score(X_test, y_test))\n",
    "    train_acc.append(tree.score(X_train, y_train))\n",
    "    \n",
    "plt.plot(max_depth, test_acc, label='Test Accuracy')\n",
    "plt.plot(max_depth, train_acc, label='Train Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Max depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chosen_depth = # Look for maximum in test curve above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "tree = DecisionTreeClassifier(max_depth=chosen_depth, class_weight=None)\n",
    "_ = tree.fit(X_train, y_train)\n",
    "\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "_ = plot_tree(tree, feature_names=X_train.columns,\n",
    "             class_names=tree.classes_,\n",
    "             filled=True, proportion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, shuffle=True)\n",
    "\n",
    "ss = StandardScaler() # KNN should use standardized data usually\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "nebrs = np.arange(1,10)\n",
    "\n",
    "test_acc, train_acc = [], []\n",
    "for n in nebrs:\n",
    "    knn = KNN(n_neighbors=n, p=2, weights='uniform')\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    test_acc.append(knn.score(X_test, y_test))\n",
    "    train_acc.append(knn.score(X_train, y_train))\n",
    "    \n",
    "plt.plot(nebrs, test_acc, label='Test Accuracy')\n",
    "plt.plot(nebrs, train_acc, label='Train Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_nebrs = # Look for maximum in test curve above\n",
    "\n",
    "knn = KNN(n_neighbors=n_nebrs, p=2, weights='uniform')\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ml_inspector.model.InspectModel import learning_curve\n",
    "learning_curve(knn, X=X_train, y=y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Consider Some Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chosen_model = knn # Or whatever model you want, for example, the tree trained previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot residuals for REGRESSION TASKS\n",
    "from ml_inspector.model.InspectModel import plot_residuals\n",
    "plot_residuals(y_train, chosen_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for CLASSIFICATION TASKS\n",
    "from ml_inspector.model.InspectModel import confusion_matrix\n",
    "confusion_matrix(knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Binary JSD (OvO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ml_utils.eda.screen import JSBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jsb = JSBinary(js_bins=25)\n",
    "_ = jsb.fit(X,y)\n",
    "_ = jsb.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jsb.top_features(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Consider some polynomial feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_std = ss.fit_transform(X)\n",
    "\n",
    "pf = PF(degree=3)\n",
    "X_std_poly = pf.fit_transform(X_std)\n",
    "\n",
    "jsb = JSBinary(js_bins=25)\n",
    "_ = jsb.fit(X_std_poly,y)\n",
    "jsb.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## OvA JSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Top Features Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ml_utils.sklearn_ext.feature_selection import JensenShannonDivergence\n",
    "js = JensenShannonDivergence(top_k=3, feature_names=X.columns, per_class=True, bins=25)\n",
    "_ = js.fit(X, y)\n",
    "\n",
    "js.visualize(by_class=True, threshold=0.7, figsize=(10,10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interesting_features= [] # Fill in interesting features from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "X_net = X.copy()\n",
    "X_net['class'] = y\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(interesting_features)/2, ncols=2, figsize=(10,20))\n",
    "for i,(a,ax) in enumerate(zip(\n",
    "    interesting_features,\n",
    "    axes.ravel()\n",
    ")):\n",
    "    ax_ = sns.boxplot(x='class', y=a, data=X_net, ax=ax)\n",
    "    _ = ax_.set_xticklabels(ax_.get_xticklabels(),rotation=90)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is an equivalent, but different summary as a heatmap\n",
    "screen = JSScreen(n=1, feature_names=X.columns, js_bins=10)\n",
    "screen.fit(X_murre, y_murre)\n",
    "screen.visualize_grid(plt.figure(figsize=(20,20)).gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = screen.visualize_classes(method='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at the distribution of the top feature for each class\n",
    "screen.visualize_max(bins=10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Look for interesting clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interest, proposed_combinations = screen.interesting(0.7, method=\"max\", min_delta=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
