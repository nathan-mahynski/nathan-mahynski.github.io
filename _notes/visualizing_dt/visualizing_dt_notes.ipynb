{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3Vid3laJLW_6",
        "TYtlz8EFJM8V",
        "vpsyC5sm46Oz",
        "OoKdH4jE56Q9",
        "1T1TTrKKJDN_",
        "cwHLBrfsOlBv",
        "9BGlqA41Onys",
        "vEUHJsK7Oyar",
        "KzZdZNEnt3CX",
        "rSiECbZGu3HB",
        "MpqIqy_ju5WE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Decision Trees\n",
        "\n",
        "Nathan A. Mahynski\n",
        "\n",
        "These are notes on using various tools like [dtreeviz](https://github.com/parrt/dtreeviz) to nicely visualize decision trees.  See their documentation for more examples and up-to-date usage."
      ],
      "metadata": {
        "id": "3Vid3laJLW_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "using_colab = 'google.colab' in str(get_ipython())\n",
        "if using_colab:\n",
        "  root_dir = './'\n",
        "  HEAD = \"https://raw.githubusercontent.com/nathan-mahynski/nathan-mahynski.github.io/public/_notes/visualizing_dt\"\n",
        "  !wget --no-check-certificate --content-disposition --no-directories -r $HEAD/cars.csv\n",
        "  !wget --no-check-certificate --content-disposition --no-directories -r $HEAD/knowledge.csv\n",
        "else:\n",
        "  import os\n",
        "  root_dir = os.getcwd()\n",
        "  \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "jCDDy1P0LXTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install watermark"
      ],
      "metadata": {
        "id": "bfoJXxLKKF2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dtreeviz==1.3.7 # This is for sklearn\n",
        "\n",
        "# dtreeviz needs the pip version of graphiviz NOT the conda ones, so you might need to uninstall\n",
        "# !conda uninstall python-graphviz\n",
        "# !conda uninstall graphviz\n",
        "\n",
        "# These are optional for other packages besides sklearn\n",
        "# !pip install dtreeviz[xgboost]    # install XGBoost related dependency\n",
        "# !pip install dtreeviz[pyspark]    # install pyspark related dependency\n",
        "# !pip install dtreeviz[lightgbm]   # install LightGBM related dependency\n",
        "\n",
        "import dtreeviz"
      ],
      "metadata": {
        "id": "55QfGMeUKEiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import watermark\n",
        "%load_ext watermark\n",
        "\n",
        "%watermark -t -m -v --iversions"
      ],
      "metadata": {
        "id": "KzlfUQxqJnDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "WCyzBbQ9oiy8"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using [scikit-learn](https://scikit-learn.org/)"
      ],
      "metadata": {
        "id": "TYtlz8EFJM8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See sklearn's [documentation](https://scikit-learn.org/stable/modules/tree.html) on visualizing decision trees.\n",
        "\n",
        "A more [detailed example](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py) illustrates things like looking over decision paths."
      ],
      "metadata": {
        "id": "j9gXXrwv047E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)"
      ],
      "metadata": {
        "id": "CPOphTFlJMUG"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "_ = tree.plot_tree(\n",
        "    clf,\n",
        "    feature_names=iris.feature_names,\n",
        "    class_names=iris.target_names,\n",
        "    filled=True,\n",
        "    proportion=True,\n",
        "    rounded=True,\n",
        "    precision=2,\n",
        "    ax=plt.gca()\n",
        "    )"
      ],
      "metadata": {
        "id": "HNpvKgUZJMgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_nodes = clf.tree_.node_count\n",
        "children_left = clf.tree_.children_left\n",
        "children_right = clf.tree_.children_right\n",
        "feature = clf.tree_.feature\n",
        "threshold = clf.tree_.threshold\n",
        "\n",
        "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
        "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
        "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
        "while len(stack) > 0:\n",
        "    # `pop` ensures each node is only visited once\n",
        "    node_id, depth = stack.pop()\n",
        "    node_depth[node_id] = depth\n",
        "\n",
        "    # If the left and right child of a node is not the same we have a split\n",
        "    # node\n",
        "    is_split_node = children_left[node_id] != children_right[node_id]\n",
        "    # If a split node, append left and right children and depth to `stack`\n",
        "    # so we can loop through them\n",
        "    if is_split_node:\n",
        "        stack.append((children_left[node_id], depth + 1))\n",
        "        stack.append((children_right[node_id], depth + 1))\n",
        "    else:\n",
        "        is_leaves[node_id] = True\n",
        "\n",
        "print(\n",
        "    \"The binary tree structure has {n} nodes and has \"\n",
        "    \"the following tree structure:\\n\".format(n=n_nodes)\n",
        ")\n",
        "for i in range(n_nodes):\n",
        "    if is_leaves[i]:\n",
        "        print(\n",
        "            \"{space}node={node} is a leaf node.\".format(\n",
        "                space=node_depth[i] * \"\\t\", node=i\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        print(\n",
        "            \"{space}node={node} is a split node: \"\n",
        "            \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
        "            \"else to node {right}.\".format(\n",
        "                space=node_depth[i] * \"\\t\",\n",
        "                node=i,\n",
        "                left=children_left[i],\n",
        "                feature=feature[i],\n",
        "                threshold=threshold[i],\n",
        "                right=children_right[i],\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "PSxTtPlp4rht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction Path"
      ],
      "metadata": {
        "id": "vpsyC5sm46Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a point to analyze\n",
        "X_test = X[:1]\n",
        "\n",
        "node_indicator = clf.decision_path(X_test)\n",
        "leaf_id = clf.apply(X_test)\n",
        "\n",
        "sample_id = 0\n",
        "# obtain ids of the nodes `sample_id` goes through, i.e., row `sample_id`\n",
        "node_index = node_indicator.indices[\n",
        "    node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
        "]\n",
        "\n",
        "print(\"Rules used to predict sample {id}:\\n\".format(id=sample_id))\n",
        "for node_id in node_index:\n",
        "    # continue to the next node if it is a leaf node\n",
        "    if leaf_id[sample_id] == node_id:\n",
        "        continue\n",
        "\n",
        "    # check if value of the split feature for sample 0 is below threshold\n",
        "    if X_test[sample_id, feature[node_id]] <= threshold[node_id]:\n",
        "        threshold_sign = \"<=\"\n",
        "    else:\n",
        "        threshold_sign = \">\"\n",
        "\n",
        "    print(\n",
        "        \"decision node {node} : (X_test[{sample}, {feature}] = {value}) \"\n",
        "        \"{inequality} {threshold})\".format(\n",
        "            node=node_id,\n",
        "            sample=sample_id,\n",
        "            feature=feature[node_id],\n",
        "            value=X_test[sample_id, feature[node_id]],\n",
        "            inequality=threshold_sign,\n",
        "            threshold=threshold[node_id],\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "b0OYk0nf4rtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ids = [0, 1]\n",
        "# boolean array indicating the nodes both samples go through\n",
        "common_nodes = node_indicator.toarray()[sample_ids].sum(axis=0) == len(sample_ids)\n",
        "# obtain node ids using position in array\n",
        "common_node_id = np.arange(n_nodes)[common_nodes]\n",
        "\n",
        "print(\n",
        "    \"\\nThe following samples {samples} share the node(s) {nodes} in the tree.\".format(\n",
        "        samples=sample_ids, nodes=common_node_id\n",
        "    )\n",
        ")\n",
        "print(\"This is {prop}% of all nodes.\".format(prop=100 * len(common_node_id) / n_nodes))"
      ],
      "metadata": {
        "id": "UQYJT8tQ48kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Boundaries"
      ],
      "metadata": {
        "id": "OoKdH4jE56Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import DecisionBoundaryDisplay \n",
        "\n",
        "# Parameters\n",
        "n_classes = 3\n",
        "plot_colors = \"ryb\"\n",
        "plot_step = 0.02\n",
        "\n",
        "\n",
        "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]):\n",
        "    # We only take the two corresponding features\n",
        "    X = iris.data[:, pair]\n",
        "    y = iris.target\n",
        "\n",
        "    # Train\n",
        "    clf = DecisionTreeClassifier().fit(X, y)\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    ax = plt.subplot(2, 3, pairidx + 1)\n",
        "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
        "    DecisionBoundaryDisplay.from_estimator(\n",
        "        clf,\n",
        "        X,\n",
        "        cmap=plt.cm.RdYlBu,\n",
        "        response_method=\"predict\",\n",
        "        ax=ax,\n",
        "        xlabel=iris.feature_names[pair[0]],\n",
        "        ylabel=iris.feature_names[pair[1]],\n",
        "    )\n",
        "\n",
        "    # Plot the training points\n",
        "    for i, color in zip(range(n_classes), plot_colors):\n",
        "        idx = np.where(y == i)\n",
        "        plt.scatter(\n",
        "            X[idx, 0],\n",
        "            X[idx, 1],\n",
        "            c=color,\n",
        "            label=iris.target_names[i],\n",
        "            cmap=plt.cm.RdYlBu,\n",
        "            edgecolor=\"black\",\n",
        "            s=15,\n",
        "        )\n",
        "\n",
        "plt.suptitle(\"Decision surface of decision trees trained on pairs of features\")\n",
        "plt.legend(loc=\"lower right\", borderpad=0, handletextpad=0)\n",
        "_ = plt.axis(\"tight\")"
      ],
      "metadata": {
        "id": "Rpo0AlCu3QWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_nodes = clf.tree_.node_count\n",
        "children_left = clf.tree_.children_left\n",
        "children_right = clf.tree_.children_right\n",
        "feature = clf.tree_.feature\n",
        "threshold = clf.tree_.threshold\n",
        "\n",
        "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
        "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
        "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
        "while len(stack) > 0:\n",
        "    # `pop` ensures each node is only visited once\n",
        "    node_id, depth = stack.pop()\n",
        "    node_depth[node_id] = depth\n",
        "\n",
        "    # If the left and right child of a node is not the same we have a split\n",
        "    # node\n",
        "    is_split_node = children_left[node_id] != children_right[node_id]\n",
        "    # If a split node, append left and right children and depth to `stack`\n",
        "    # so we can loop through them\n",
        "    if is_split_node:\n",
        "        stack.append((children_left[node_id], depth + 1))\n",
        "        stack.append((children_right[node_id], depth + 1))\n",
        "    else:\n",
        "        is_leaves[node_id] = True\n",
        "\n",
        "print(\n",
        "    \"The binary tree structure has {n} nodes and has \"\n",
        "    \"the following tree structure:\\n\".format(n=n_nodes)\n",
        ")\n",
        "for i in range(n_nodes):\n",
        "    if is_leaves[i]:\n",
        "        print(\n",
        "            \"{space}node={node} is a leaf node.\".format(\n",
        "                space=node_depth[i] * \"\\t\", node=i\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        print(\n",
        "            \"{space}node={node} is a split node: \"\n",
        "            \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
        "            \"else to node {right}.\".format(\n",
        "                space=node_depth[i] * \"\\t\",\n",
        "                node=i,\n",
        "                left=children_left[i],\n",
        "                feature=feature[i],\n",
        "                threshold=threshold[i],\n",
        "                right=children_right[i],\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "TanBhTmV4irR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using [dtreeviz](https://github.com/parrt/dtreeviz)"
      ],
      "metadata": {
        "id": "1T1TTrKKJDN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can read more about this package and why design decisions were made [here](https://explained.ai/decision-tree-viz/index.html)"
      ],
      "metadata": {
        "id": "N-kcbxQFwtdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.datasets import load_boston, load_iris, load_diabetes"
      ],
      "metadata": {
        "id": "iZLyV1CqMPwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dtreeviz.trees import *"
      ],
      "metadata": {
        "id": "m33GSzVeMtMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression"
      ],
      "metadata": {
        "id": "cwHLBrfsOlBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regr = tree.DecisionTreeRegressor(max_depth=3)\n",
        "boston = load_boston()\n",
        "\n",
        "X_train = boston.data\n",
        "y_train = boston.target\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "viz = dtreeviz(regr,\n",
        "               X_train,\n",
        "               y_train,\n",
        "               target_name='price',  # this name will be displayed at the leaf node\n",
        "               feature_names=boston.feature_names,\n",
        "               title=\"Boston data set regression\",\n",
        "               fontname=\"Arial\",\n",
        "               title_fontsize=16,\n",
        "               colors = {\"title\":\"purple\"}\n",
        "              )\n",
        "viz\n",
        "# viz.view() will give give a popup with graph in pdf"
      ],
      "metadata": {
        "id": "js_LEhk7JLhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "9BGlqA41Onys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = tree.DecisionTreeClassifier(max_depth=2)  # limit depth of tree\n",
        "iris = load_iris()\n",
        "classifier.fit(iris.data, iris.target)\n",
        "\n",
        "viz = dtreeviz(classifier, \n",
        "               iris.data, \n",
        "               iris.target,\n",
        "               target_name='variety',\n",
        "               feature_names=iris.feature_names, \n",
        "               class_names=[\"setosa\", \"versicolor\", \"virginica\"]  # need class_names for classifier\n",
        "              ) \n",
        "\n",
        "viz "
      ],
      "metadata": {
        "id": "p_8kuEJtJLjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = tree.DecisionTreeClassifier(max_depth=2)  # limit depth of tree\n",
        "iris = load_iris()\n",
        "classifier.fit(iris.data, iris.target)\n",
        "\n",
        "viz = dtreeviz(classifier, \n",
        "               iris.data, \n",
        "               iris.target,\n",
        "               target_name='variety',\n",
        "               feature_names=iris.feature_names, \n",
        "               class_names=[\"setosa\", \"versicolor\", \"virginica\"],  \n",
        "               fancy=False # fancy=False to remove histograms/scatterplots from decision nodes\n",
        "              ) \n",
        "\n",
        "viz "
      ],
      "metadata": {
        "id": "c4UQl3wHJLz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction Path"
      ],
      "metadata": {
        "id": "vEUHJsK7Oyar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Highlights the decision nodes in which the feature value of single observation \n",
        "# passed in argument X falls. Gives feature values of the observation and \n",
        "# highlights features which are used by tree to traverse path.\n",
        "\n",
        "regr = tree.DecisionTreeRegressor(max_depth=2)  # limit depth of tree\n",
        "diabetes = load_diabetes()\n",
        "regr.fit(diabetes.data, diabetes.target)\n",
        "X = diabetes.data[np.random.randint(0, len(diabetes.data)),:]  # random sample from training\n",
        "\n",
        "viz = dtreeviz(regr,\n",
        "               diabetes.data, \n",
        "               diabetes.target, \n",
        "               target_name='value', \n",
        "               orientation ='LR',  # left-right orientation\n",
        "               feature_names=diabetes.feature_names,\n",
        "               X=X)  # need to give single observation for prediction\n",
        "              \n",
        "viz"
      ],
      "metadata": {
        "id": "MPlGI2RxOa4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtreeviz(regr,\n",
        "        diabetes.data, \n",
        "        diabetes.target, \n",
        "        target_name='value', \n",
        "        orientation ='TD',  # top-down orientation\n",
        "        feature_names=diabetes.feature_names,\n",
        "        X=X, # need to give single observation for prediction\n",
        "        show_just_path=True     \n",
        "        )"
      ],
      "metadata": {
        "id": "IbaaCk03owQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(explain_prediction_path(regr, X, feature_names=diabetes.feature_names, \n",
        "                              explanation_type=\"plain_english\"))"
      ],
      "metadata": {
        "id": "3f-s4ljEpKDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "print(explain_prediction_path(regr, X, feature_names=diabetes.feature_names, \n",
        "                              explanation_type=\"sklearn_default\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "74DVQ-Cbpdy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature-target space"
      ],
      "metadata": {
        "id": "KzZdZNEnt3CX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression"
      ],
      "metadata": {
        "id": "rSiECbZGu3HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = os.path.join(root_dir, \"cars.csv\")"
      ],
      "metadata": {
        "id": "mc3CMYpv0BGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression univariate feature-target space\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "df_cars = pd.read_csv(output)\n",
        "X, y = df_cars[['WGT']], df_cars['MPG']\n",
        "\n",
        "dt = DecisionTreeRegressor(max_depth=3, criterion=\"absolute_error\")\n",
        "dt.fit(X, y)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca()\n",
        "rtreeviz_univar(dt, X, y, feature_names='WGT', target_name='MPG', ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wqGEQZO6tnGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression bivariate feature-target space\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from dtreeviz.trees import *\n",
        "\n",
        "df_cars = pd.read_csv(output)\n",
        "X = df_cars[['WGT','ENG']]\n",
        "y = df_cars['MPG']\n",
        "\n",
        "dt = DecisionTreeRegressor(max_depth=3, criterion=\"mae\")\n",
        "dt.fit(X, y)\n",
        "\n",
        "figsize = (12,8)\n",
        "fig = plt.figure(figsize=figsize)\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "t = rtreeviz_bivar_3D(dt,\n",
        "                      X, y,\n",
        "                      feature_names=['Vehicle Weight', 'Horse Power'],\n",
        "                      target_name='MPG',\n",
        "                      fontsize=14,\n",
        "                      elev=20,\n",
        "                      azim=25,\n",
        "                      dist=8.2,\n",
        "                      show={'splits','title'},\n",
        "                      ax=ax)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "2PZfzIJ3uCgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression bivariate feature-target space heatmap\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from dtreeviz.trees import *\n",
        "\n",
        "df_cars = pd.read_csv(output)\n",
        "X = df_cars[['WGT','ENG']]\n",
        "y = df_cars['MPG']\n",
        "\n",
        "dt = DecisionTreeRegressor(max_depth=3, criterion=\"mae\")\n",
        "dt.fit(X, y)\n",
        "\n",
        "t = rtreeviz_bivar_heatmap(dt,\n",
        "                           X, y,\n",
        "                           feature_names=['Vehicle Weight', 'Horse Power'],\n",
        "                           fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HF-frJc1up-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification"
      ],
      "metadata": {
        "id": "MpqIqy_ju5WE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = os.path.join(root_dir, \"knowledge.csv\")"
      ],
      "metadata": {
        "id": "a3N6BOkN0GOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification univariate feature-target space\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from dtreeviz.trees import *\n",
        "\n",
        "know = pd.read_csv(output)\n",
        "class_names = ['very_low', 'Low', 'Middle', 'High']\n",
        "know['UNS'] = know['UNS'].map({n: i for i, n in enumerate(class_names)})\n",
        "\n",
        "X = know[['PEG']]\n",
        "y = know['UNS']\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=3)\n",
        "dt.fit(X, y)\n",
        "\n",
        "ct = ctreeviz_univar(dt, X, y,\n",
        "                     feature_names = ['PEG'],\n",
        "                     class_names=class_names,\n",
        "                     target_name='Knowledge',\n",
        "                     nbins=40, gtype='strip',\n",
        "                     show={'splits','title'})\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k2srYaaAuqGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification bivariate feature-target space\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from dtreeviz.trees import *\n",
        "\n",
        "know = pd.read_csv(output)\n",
        "print(know)\n",
        "class_names = ['very_low', 'Low', 'Middle', 'High']\n",
        "know['UNS'] = know['UNS'].map({n: i for i, n in enumerate(class_names)})\n",
        "\n",
        "X = know[['PEG','LPR']]\n",
        "y = know['UNS']\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=3)\n",
        "dt.fit(X, y)\n",
        "\n",
        "ct = ctreeviz_bivar(dt, X, y,\n",
        "                    feature_names = ['PEG','LPR'],\n",
        "                    class_names=class_names,\n",
        "                    target_name='Knowledge')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h7tteeqjvG4X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}