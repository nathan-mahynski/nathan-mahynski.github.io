---
title: "Random Forests"
excerpt: "Perhaps the best ensemble method for tabular data."
header:
  teaser: /assets/img/random_forest_cartoon.png
tags:
  - machine learning
  - ensemble
  - random forest
classes:
  - wide
---

{% include toc icon="gears" title="Table of Contents" %}

## Summary

{% include gallery caption="Caption." %}

See youtube and medium, python ml book
Jeremy howard

reference baggin vs boosting notes

baggin of decision trees
can use intinsic class balancing
fast and easy to train
not very sensative to hyperparameters (easy to CV)
wonderful theorteticl properties
usually (one of) the best performers for dense tabular data
can be trained in parallel execution
regression or classification
